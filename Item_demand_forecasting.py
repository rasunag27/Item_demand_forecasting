# -*- coding: utf-8 -*-
"""Final_Item_demand_forecasting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17EQ2tp8LnVd_0Q4ym_t3SOkh5HkhOvWt

# Import general libraries
"""

import numpy as np
import pandas as pd
import time
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

import warnings
warnings.filterwarnings("ignore")

"""# Import ML libraries

Install fbprophet model
"""

!pip install pystan

"""Import prophet libraries"""

from fbprophet import Prophet
from fbprophet.diagnostics import cross_validation
from fbprophet.diagnostics import performance_metrics

"""Import ML models"""

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
import xgboost as xgb
from sklearn.metrics import r2_score
from datetime import datetime

"""# Import dataset"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Datasets/item_forecast.csv')
df.head()

def basic_eda(df):
  print("######## Shape ########")
  print(df.shape)
  print("######## types ########")
  print(df.dtypes)
  print("######## head #########")
  print(df.head())
  print("######## tail #########")
  print(df.tail())
  print("######## isnull ########")
  print(df.isnull().sum())

basic_eda(df)

# Convert sales to type float
df['sales'] = df['sales'].astype(float)

df.info()

df.isnull().sum()

print('No of stores:',df['store'].nunique())
print('No of items:',df['item'].nunique())

df['date'] = pd.to_datetime(df['date'])

df.dtypes

df1 = pd.pivot_table(df, values = "sales", index="date", columns = "item", aggfunc = np.sum)
df1

df_date_item = df.groupby(["date","item"])["sales"].sum().reset_index()
df_date_item

fig = px.line(df_date_item, x='date', y='sales')
fig.show()

"""# Rolling mean of 90 day sales"""

df_date_item['moving_average'] = df_date_item['sales'].rolling(window = 90).sum().shift(-89)

fig = px.line(df_date_item, x='date', y='moving_average')
fig.show()

# Replace column names and convert to dataframe

df1.columns = [ 'item_' + str(i) for i in range(1,len(df1.columns)+1)]
df1 = df1.reset_index()
df1

"""Rolling mean graph for all items"""

def moving_avg(df1):
  for i in df1.columns[1:6]:
    sales = df1[i].rolling(window=90).sum().shift(-89)
    fig = px.line(df1, x='date', y=sales)
    fig.update_layout(title_text=str(i))
    fig.show()

moving_avg(df1)

"""Inference

From the graph, we see that
1. There is a seasonality monthly trend.
2. There is an yearly trend. The graph indicates the increase of sales year by year.

# FbProphet model

Let us model for 1 item completely and then apply same procedure to all and provide the metrics for all items.
"""

def data_prophet(item_number):
  item_data = {"ds": [], "y": []}

  for i in range(len(df1)):
      item_data["ds"] = df1['date']
      item_data["y"] = (df1[item_number].rolling(window=90).sum().shift(-89))
  item_data = pd.DataFrame(item_data)
  item_data.dropna(inplace=True) # Removal of nan values which occured due to moving average
  return item_data

# Function for fitting the model for training dataset.

def model_fit(item_number):
  #Calling the dataframe for specific item
  item_data = data_prophet(item_number) #Function call - data(item_number)
  train, test = item_data[item_data['ds'] <= '2016-12-31'], item_data[item_data['ds'] > '2016-12-31']
  model = Prophet(interval_width = 0.80, changepoint_range = 0.9, daily_seasonality=True)
  #model = Prophet(changepoint_range=0.9)
  model.fit(train)

  return item_data, train, test, model

# Model prediction - Main function -> This includes data aggregation function and model fitting function.
def model_prediction_prophet(item_number, periods):
  # Calling model_fit function
  item_data, train, test, model = model_fit(item_number)
  future_dates = model.make_future_dataframe(periods = periods)
  forecast = model.predict(future_dates)
  return item_data, train, test, model, forecast

# Main function call which predicts the data from data aggregation, model fitting to training and predicton
item_data, train, test, model, forecast = model_prediction_prophet('item_1', 276)
model.plot(forecast)

model.plot_components(forecast)

from fbprophet.plot import add_changepoints_to_plot
fig = model.plot(forecast)
a = add_changepoints_to_plot(fig.gca(), model, forecast)

from fbprophet.plot import plot_plotly
import plotly.offline as py

fig = plot_plotly(model, forecast)
py.iplot(fig)

deltas = model.params['delta'].mean(0)
def plot_changepoint(deltas):
  fig = plt.figure(facecolor = 'w')
  ax = fig.add_subplot(111)
  ax.bar(range(len(deltas)), deltas)
  ax.grid(True, which = 'major', c = 'red', ls = '-', lw = 1, alpha = 0.2)
  ax.set_xlabel('Rate Change')
  ax.set_ylabel('Changepoint')
  fig.tight_layout()

plot_changepoint(deltas)

"""Lets find the r2 score for item_1 from fbprophet method"""

plot_data = {"y_true": [], "y_pred": []}

plot_data['y_true'] = test['y']
plot_data['y_pred'] = forecast[len(train):]['yhat']
plot_data = pd.DataFrame(plot_data)

fig = px.line(plot_data, x = test['ds'], y = ["y_true", "y_pred"])
fig.update_layout(
    title="Item 1 90_day_sales - forecast prediction - fbProphet", xaxis_title="Date", yaxis_title="Sales"
)
fig.show()

"""R2 Score"""

def r2_metric(test, forecast):
  y_true = test['y']
  y_pred = forecast[len(train):]['yhat']
  r2_metric = r2_score(y_true, y_pred)
  return r2_metric

r2_metric = r2_metric(test, forecast)
print('The R2 score of 90 day prediction of Item 1 is:', r2_metric)

"""# ML Models

From the graph, we found that
1. There is a seasonality monthly trend.
2. There is an yearly trend. The graph indicates the increase of sales year by year.

Based on these analysis, we shall add week, year and also day as additional feature in our model. 

From these features, we shall build the model using Linear Regression, Decision Tree, Random forest and XGBoost. The model is built with default parameters.

Since it a regression problem, we shall compare each model with the R2 score.
"""

def data_ml(item_number):
  item_data = {"date": [], "90_day_sales": []}

  for i in range(len(df1)):
      item_data["date"] = df1['date']
      item_data["90_day_sales"] = (df1[item_number].rolling(window=90).sum().shift(-89))
  item_data = pd.DataFrame(item_data)
  item_data.dropna(inplace=True) # Removal of nan values which occured due to moving average
  item_data['day']=item_data['date'].dt.day
  item_data['week']=item_data['date'].dt.week
  item_data['year']=item_data['date'].dt.year
  #item_data = item_data.iloc[::7]
  #item_data.set_index('date',inplace=True)
  return item_data

#df_item1=df_item1.iloc[::7]

"""Lets model for Item 1 first"""

item_data = data_ml('item_1')

"""Train and test split"""

def train_test_split(item_data):
  X_train=item_data[item_data['date'] <= '2016-12-31'].drop(['90_day_sales'],axis=1)
  X_train.set_index('date',inplace=True)
  X_test=item_data[item_data['date'] > '2016-12-31'].drop(['90_day_sales'],axis=1)
  X_test.set_index('date',inplace=True)
  Y_train=item_data['90_day_sales'].iloc[0:len(X_train)]
  Y_test=item_data['90_day_sales'].iloc[len(X_train):]#making train and test datasets
  return X_train, X_test, Y_train, Y_test

X_train, X_test, Y_train, Y_test = train_test_split(item_data)

def predict_plot(model,title):
  model.fit(X_train,Y_train)
  pred=model.predict(X_test)
  yt = Y_test.to_frame()
  yt['prediction'] = pred
  yt['date'] = test['ds']
  r2_metric = r2_score(Y_test, pred)
  fig = px.line(yt, x='date', y=['90_day_sales', 'prediction'], title = title)
  fig.update_layout(
  autosize=False,
  width=600,
  height=300,)

  return r2_metric, fig

import xgboost as xgb
xgb=xgb.XGBRegressor()
r2_metric_lr, fig_lr = predict_plot(LinearRegression(),'LinearRegression')
r2_metric_dt, fig_dt = predict_plot(DecisionTreeRegressor(),'DecisionTree')
r2_metric_rf, fig_rf = predict_plot(RandomForestRegressor(),'RandomForest')
r2_metric_xgb, fig_xgb = predict_plot(xgb,'XGBoost')

print('The r2 score of linear regression model is:', r2_metric_lr)
print('The r2 score of Decision tree model is:', r2_metric_dt)
print('The r2 score of Random forest model is:', r2_metric_rf)
print('The r2 score of XGB regression model is:', r2_metric_xgb)

fig_lr.show()

fig_dt.show()

fig_rf.show()

fig_xgb.show()

"""# Best model for all items"""

models=["LinearRegression","DecisionTree","RandomForest","XGBoost"]

time_period = 276
for i in df1.columns[1:]:
  # Prophet
  item_data, train, test, model, forecast = model_prediction_prophet(i, time_period)
  y_true = test['y']
  y_pred = forecast[len(train):]['yhat']
  r2_prophet = r2_score(y_true, y_pred)

  # ML models
  item_data = data_ml(i)
  X_train, X_test, Y_train, Y_test = train_test_split(item_data)
  r2_metric_lr, fig_lr = predict_plot(LinearRegression(),'LinearRegression')
  r2_metric_dt, fig_dt = predict_plot(DecisionTreeRegressor(),'DecisionTree')
  r2_metric_rf, fig_rf = predict_plot(RandomForestRegressor(),'RandomForest')
  r2_metric_xgb, fig_xgb = predict_plot(xgb,'XGBoost')

  r2 = [r2_metric_lr, r2_metric_dt, r2_metric_rf, r2_metric_xgb]
  r2_max = r2.index(max(r2))

  if r2_prophet > r2_max:
    print('The best model for ' + i + ' is Prophet model and r2 score is:', r2_prophet)
  else:
    print('The best model for ' + i + ' is',models[r2_max],'and the r2 score is', max(r2))

"""# Future prediction at particular day, week and year for specific item."""

def predict_future(item_number, day, week, year):
  # item and train data
  item_data = data_ml(item_number)
  X_train, X_test, Y_train, Y_test = train_test_split(item_data)

  p = [day, week, year]
  p = np.array(p).reshape((1, -1))
  p = pd.DataFrame(p, columns = ['day', 'week', 'year'])

  # model
  model = DecisionTreeRegressor()
  model.fit(X_train,Y_train)
  pred=model.predict(p)
  return pred, item_number

pred, item_number = predict_future('item_4', 30, 46, 2016)
print('The predicted next 90 day sales for',item_number, 'is:',pred[0])